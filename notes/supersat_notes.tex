\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{url}
\usepackage{color}
\usepackage{titlesec}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{amsfonts}
\usepackage{hyperref}
\graphicspath{{../figures/}}

\title{notes: supersat}
\author{K. Latimer}
\date{Jan 13, 2020}

\begin{document}

\maketitle

\section{CAIPEEX}

\section{HALO}
\subsection{Data processing}
\begin{itemize}
	\item I did some manual cleanup on my Windows partition in earlier stages of the project for the HALO .ames files downloaded from the online database. The .ames conventions are defined \href{http://artefacts.ceda.ac.uk/formats/NASA-Ames/na-brief-guide.html}{here} and there was some degree of human error in following them. The correction process is documented in the ipython notebook file \texttt{HALO\_file\_processing.ipynb} and summarized in the text file ``HALO\_cleanup\_notes," both in notes/ subdirectory. The resulting raw data files are what I have saved in /data/halo/ames, and are the input for further processing by \texttt{halo\_data\_cleanup.py}. Note that some files from the GoAMAZON campaign have been excluded from that processing for various reasons (weird ames format, missing data, etc).
	\item 1/12/20: noticed some files had weird error values and changed them manually. Not sure why previous code didn't find those. Recorded in ``HALO\_cleanup\_notes".
	\item 1/14/20: noticed data missing in 3914. see ``HALO\_cleanup\_notes".
\end{itemize}

\subsection{Analysis}
For the record: feedback from R Weigel RE: disparate particle size PDFs between CAS and CDP instruments (bold emphasis mine):

{\itshape Related to the plots you have distributed (15 Nov 2019), it is not clear and difficult for us to judge whether the extracted particle concentrations were normalized to respective (and variable) bin width specified in the header of the data file.

The plots obviously show different size resolutions for the individual instruments, which disables a direct comparison of these data as the compared size bins are not equivalent.

One of our major concerns is that averaging over an entire flight causes an averaging over various cloud types and different developing stages of clouds. From take-off through landing, the averaging runs over liquid, mixed and ice phases at different atmospheric conditions and cloud ages. In addition to the non-equivalently binned data sets, the averaging over various cloud types could lead to misinterpretations. For instance, the spikes that you interpreted as CDP’s ``over-reporting" in sizes of 10, 20, 30 µm (not size-resolved by the CAS) could result from (natural) cloud particle modes within different cloud types and/or at different development stages. \textbf{We suggest to limit the instrumental comparison to individual events of cloud encounters which may then be sorted by cloud types or atmospheric condition.}

Furthermore, \textbf{we suggest to consider differences in the data sets which may result from corrections of the sampled air volume based on the air speed. In terms of true air speed (TAS) or probe air speed (PAS), the data sets as given on the database are not equivalent. You can transfer the CAS data set to the standard of the CDP.} The needed calculations conclude from the instructions given in the data headers. However, for any comparison, the data sets should be consistent.

Finally, \textbf{we suggest once more to include also the NIXE-CAPS data sets} and to involve the colleagues in this discussion to better evaluate the deviation of the instruments’ data from each other also in the view of the instruments’ uncertainty.

From our point of view, at current stage, there is no unambiguous indication, which instrument is``over-" or ``under-reporting" something.}

\begin{itemize}
	\item 1/15/20: NIXE-CAPS data contains no time steps (for any flight) where all bins up to 52um diameter have non-error values (see \texttt{search\_NIXECAPS.py}). ADLR LWC values differ significantly from CAS and CDP...possibly includes rain droplets? See `comparelwc' figure. Also looked at effect of excluding size bins w/ mean diam $<$ 3um, and using `xi' correction factor on CAS; see `1001XX' figure.
	\item 1/17/20: reran \texttt{comparelwc\_set\_figsrc.py} --$>$ `v2' figure files. Just some aesthetic adjustments from v1: change colors, plot CAS second since it's usually smaller, sort time for 20140906 CAS data set. 
	\item 1/20/20: refigured raw data files to include lwc calculated values because it was taking too long to run those each time I made figures. General observations for comparelwc plots: 
		\begin{itemize}
			\item In general (see two notes down), ADLR lwc values from ames files are much larger than those calculated from CAS/CDP files...unclear what ADLR is including as liquid water but probably counts rain as well as cloud drops?
			\item Roughly three classifications: 1) missing data (either some or all of CAS and/or CDP) [0906, 0921, 0923, 0925, 1003, 1004]; 2) CAS and CDP data both present but peaks have significan mismatch [0919]; 3) CAS and CDP data both (reasonably) complete and peaks mostly match [0909, 0911, 0912, 0916, 0918, 0927, 0928, 0930, 1001]. 
			\item Out of the second two categories, the following have CAS/CDP peaks higher than ADLR lwc curve: 0912, 0916, 0918, 0928, 0930, 1001 - seems weird if ADLR is a superset of those as mentioned above
			\item Found some odd peak features with very small (generally under 1.e-5) lwc values when looking at 1001 dataset - code and figure (`v4comparelwc...') in scratch folder. 
		\end{itemize}
	\item 1/21/20: a few things...
		\begin{itemize}
			\item Following up on last point from yesterday: a couple of variations on comparelwc figure set: `v3': log scaling on y-axis...a bit hard to look at, hence `v4': zoom in to lower ($<$1.e-4) lwc regime. Noticed features that aren't visible at default scale, esp `several' (rough estimate only from skimming through) peaks still hitting 1.e-5 cutoff in: 0911, 0916, 0919, 0923, 0925, 0928, 1001. 
			\item I can't figure out a nice programatic way to separate cloud events without making a bunch of arbitrary decisions about selection parameters (peaks are not always cleanly delimited) so just doing manually for a couple of dates at this point. Chose 0909 and 1001 because CAS and CDP peaks roughly match so I can sort them out by eye; 1001 has the feature mentioned above that CAS/CDP lwcs can be higher than ADLR whereas 0909 does not, additionally 1001 has several of those small features discussed in preceeding point whereas 0909 has less - however, the total particle size PDFs we sent to Germany PI's are qualitatively similar so thought this was a good pair to examine side-by-side. 
		\end{itemize}
	\item 1/27/20: comparelwc set v5: include vertical wind velocity data on dual y-axis to figure out extent of error periods (hard to tell from looking at files)
	\item 1/28/20: Various notes on cloudevents figure set:
		\begin{itemize}
			\item Also added 0911 flight since a lot of vertical wind velocity data are missing from 1001 (no particular reason other than 0911 has roughly matching peaks between CAS and CDP and also roughly agrees with ADLR).
			\item Realized I should be plotting nconc/dr in upper left panel (just as I'm plotting nconc*r/dr in lower left panel)
			\item Can replace nconc/meanr vs t panel (lower right on top) with w/A vs t - generally A doesn't vary more than a few percent within a given cloud (order $10^{-2}$). Vertical wind velocity is missing for significant portion of all datasets...possibly concerning? Check with David (also see v5 comparelwc figure set).
			\item I went through all the cloudevent figures manually looking at nconc PDFs and particle size PDFs. I was looking for whether the curves for CAS and/or CDP were unimodal (i.e. a single global maximum, but allowed to be at the boundary of the domain). I excluded the lowest three bins for CAS and the lowest two bins for CDP (i.e., lower bin cutoff must be greater than 3um diameter (1.5um radius), per advice from Germany PIs). Results below in Table \ref{unimodal}. CAS definitely better by this metric; main problem with CDP seems to be 6th bin (11.8-15.6um radius range), which tends to report low relative to other bins. For cloud events where both instruments give unimodal curves, CAS pretty much always reports lower nconc and meanr (as we expect from LWC values).
		\end{itemize}
\end{itemize}
\begin{table}[ht]
\centering
\begin{tabular}{lllllll}
	Date & # cloud events & Unimodal set(s) & Count - nconc PDF& Count - meanr PDF\\
0909 & 47                 &                   &                          &                          \\
     &                    & Both     & 19                       & 21                       \\
     &                    & Only CAS & 28                       & 26                       \\
     &                    & Only CDP & 0                        & 0                        \\
     &                    & Neither  & 0                        & 0                        \\
     &                    & Excluded & 0                        & 0                        \\
0911 & 76                 &                   &                          &                          \\
     &                    & Both     & 33                       & 33                       \\
     &                    & Only CAS & 31                       & 28                       \\
     &                    & Only CDP & 0                        & 0                        \\
     &                    & Neither  & 5                        & 8                        \\
     &                    & Excluded & 7                        & 7                        \\
1001 & 32                 &                   &                          &                          \\
     &                    & Both     & 7                        & 7                        \\
     &                    & Only CAS & 17                       & 13                       \\
     &                    & Only CDP & 0                        & 0                        \\
     &                    & Neither  & 0                        & 4                        \\
     &                    & Excluded & 8                        & 8                       
\end{tabular}
\caption{Counts of unimodal curves based on cloudevents figure set. `Excluded' cloud events are due to either large mismatch between CAS and CDP for that cloud, or isolated spikes in one bin measurement for that cloud.}
\label{unimodal}
\end{table}


\section{WRF}
		\subsection{Lawrencium account}
		username: kalatimer\\
		enter in terminal: \texttt{ssh kalatimer@lrc-login.lbl.gov}\\
		type: pin (sandwiched between two sevens) + 6-digit auth code from authy chrome app (kt's token 2) [no space between]\\
		wrf folder: /clusterfs/stratus/dromps/wrf\_fan2018
\end{document}
